[TOC]



### 1. 前言

### 2. 背景知识

#### 2.1 神经网络

神经网络最初的称呼是人工神经网络（Artificial Neural Network），因为当时的研究人员是出于模拟人类大脑的目的而开发出这种模型。先驱性的工作包括MP神经元和感知机（Perceptron）。1943年，McCullogh和Pitts在一篇名为“A logic calculus of the ideas immanent in nervous activity”的论文中，给出了一个高度精简的神经元模型，我们称之为MP神经元。它的主要工作流程是：接收多个信号输入w；计算加权和s=wx；如果s大于预设阈值theta，输出一个正信号，否则，什么都不输出（也可以认为是输出0）。通过选取恰当的接收权值w，我们可以使得神经元的输入输出关系和某些函数一致，比如逻辑或（OR）和逻辑与（AND）。MP神经元的出现非常鼓舞人心，似乎我们成功踏出了探索人脑的第一步，但是它不具备人脑那样的自动学习功能，因为权值w是需要预先计算好的，所以MP神经元实质上和一个数字逻辑电路没有区别。它的主要贡献是，首次提出了神经元这种基本的计算模型。基于该模型，Rosenblatt在1958年提出了一种具备学习功能的算法，其基本计算模型和MP神经元没有区别，不过是额外提出了一种自动求解权重的方法，合称为感知机。从机器学习的角度看，感知机得到的其实是一个线性二分类器，假设数据集是线性可分的，学习算法保证了一定可以在有限次更新后找到一个将两类完美分开的超平面。从下图可以看出，OR和AND运算都可以用感知机模拟，但是XOR就不行了。

![OR、AND和XOR的分界面](http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif)

##### 2.1.1 前馈神经网络

感知机计算出的是一个在输入空间的线性分类函数，但在实际应用中，分界线几乎不可能是线性的。不过，在其他空间中，这些点可能存在线性分界线。这提示我们添加额外的转换过程。下图展示了如何通过不断的折叠，使得非线性分界线越来越接近线性。折叠操作可以通过绝对值函数实现，折叠的轴线通过一个感知机定义。

<img src="https://cdn-images-1.medium.com/max/1600/1*RRuaYJIdEH8E3bL9oySR7A.png" height="150px"/>

这样的充当转换功能的层被称为隐含层，因为它对应的数据即不是输入也不是输出。前馈神经网络包含至少一个隐含层，更一般的定义是多个神经预元节点连接形成的一个有向无环图，但是通常这些节点会被组织为一层一层的，整个模型是一个简单、统一的层叠式网络，如图所示。典型的前馈神经网络是全连接的，每个节点会和前后相邻的两层的所有节点相连，但是层内的节点没有连接。隐含层的层数和每层节点数是可以自由配置的，网络的拟合能力是和这两个量正相关的。找到一个好的配置并不容易，太多节点会导致网络过于完美的拟合训练集，太少节点的网络不足以表达数据的分布。包含一个隐含层的前馈神经网络具备全局近似能力，1989年Horniket等人证明了使用足够多的隐含层节点，网络可以以任意精度逼近任意一个函数。这告诉我们神经网络模型可以用于解决任何映射学习问题，但是这个理论在实际应用中并没有什么指导价值，因为它只给出了一个非常大的上限，而且没有给出下限。对于一个具体的任务，我们仍然无法知道多少个节点数量是合适的。



<img src="http://neuralnetworksanddeeplearning.com/images/tikz41.png" height="300px"/>

前馈神经网络可以被看成一个通用的回归或分类模型。和其他机器学习模型的求解方法一样，我们需要先定义一个损失函数，该函数的值代表了网络目前的行为和数据集的接近程度。训练的过程是调整网络的连接权值，使得损失函数在训练集上的均值尽量小。使用最广泛的优化方法是梯度下降法，该算法收敛到全局最优的条件是优化对象是一个凸函数。尽管多层神经网络的损失函数不具备这样的性质，但在实际使用中，梯度下降法几乎总能得到不错的结果。这一点可能和高维度的特性相关。



基本组成单元 基本结构 拟合能力、可训练性 比较成功的应用 hinton文章，多隐含层的表达能力

##### 2.1.2 后向传播

梯度下降法的基本思路是求出目标函数对自变量（权值）的梯度，然后向梯度的反方向更新权值。后向传播（BackPropogation，简称BP）算法是一种高效的梯度计算方法，由Werbos在19xx年首次提出，后来Hinton等人再次独立提出。之所以出现同一个研究成果被多次提出，是因为当年正处于“AI寒冬”，神经网络会议稀少，研究人员之间缺乏交流。这种算法的基本思想是利用后一层节点的梯度计算当前层的权值的梯度，这样计算整个网络的参数的梯度的复杂度是O（N+M），N是节点数量，M是连接数量。BP算法在神经网络领域享有很高的荣誉，很多人认为它的出现使得多层神经网络的训练才得以解决，然而笔者认为它不过是复合函数求导中的级联法则的一个简单应用。完全抛开BP算法，我们照样可以求出参数的梯度，只是效率会低一些。它解决的只是训练得快不快的问题，而不是能不能训练的问题。因此，可以认为BP算法被严重过誉了。目前，神经网络的可训练性仍旧是一个开放的问题。

#### 2.2 卷积神经网络

相同：卷积神经网络和前馈神经网络非常相似，都是由一些包含可学习的权值的神经元构成。每个神经元从前一层接收输入，执行点积运算，然后通过一个非线性激活函数转换特征空间。整个网络仍然表达了一个函数，自变量是图像像素，因变量是某种高层信息的分数，比如图像属于某些类别的概率。

![NN vs CNN](http://cs231n.github.io/assets/cnn/cnn.jpeg)

不同：不过，卷积神经网络是专为图像数据设计的，其层与层的连接方式有变化，训练方式也有一定变动。前馈神经网络的每个神经元的输入包括了前一层的所有单元，这种连接方式并不适用于图像数据。虽然图像有确切的尺寸，维度是固定的，但它并不是严格意义上的结构化数据，因为某个维度表达的语义并不明确。图像的特点是局部相关，任意截取一个小块，都可以归纳出某种模式，比如图像左右两部分的颜色差异较大的是一个边界，中间和两边差异较大的是一条线段，这种可归纳性在图像的每个局部都成立。而图像整体并不具备这样的特性，因为图像生成的机制实在是太复杂了。卷积神经网络可被看成一种递归滤波。像素的简单组合是线条，线条的简单组合是纹理，而纹理的简单组合就可能是某种物体了。卷积神经网络的每一层的神经元构成一个三维结构，由宽度、高度和通道数定义。每个神经元只和前一层的某个区域的神经元相连接，同层的不同节点和前一层的连接权重是共享的，这和全连接有明显的区别。

##### 2.2.1 CNN的结构

典型的CNN由卷积层、Pooling层和全连接层组成。

卷积层由多个可学习的滤波器（filter）组成。滤波器是三维的，其长度和宽度都比较小，一般限制在10以内，通道数和输入保持一致。卷积其实是一个滑动的过程，滤波器在输入特征的横向和纵向方向上移动，每个位置上单独计算点积，得到的是一个二维的特征图。特征图的值代表了输入特征的各个局部和滤波器的相似程度。卷积层由三个主要的超参数定义：滤波器数量、滤波器尺寸和滑动步长。滤波器的数量会显著影响卷积层的表达力，因为每个滤波器学习到的都是独立的模式，更多的滤波器可以提取到更丰富的信息。比如作用于原始图像的第一层卷积层，需要捕捉不同方向的线条、不同颜色的色块等。一个卷积层通常包含了几十到几百个滤波器，每个独立产生一个二维特征图。这些特征图堆叠起来就是卷积层的输出。滤波器的尺寸也会影响卷积层的表达力和稳定性。大卷积核能够提取到复杂的模式，但是也可能捕捉到噪音；小卷积核提取的是小范围的简单模式。将多个小卷积核级联可以获得更大的视野范围，比如两层3*3的卷积核的表达力等价于一层5、5的。实验表明，降低卷积核的尺寸并增加网络的层数可以获得泛化能力更好的网络。滑动步长决定了输出的特征图是否会被降采样。可以单独设置横向和纵向的步长，不过一般两个值相等，以s表示。若s为1，那么输出特征图的尺寸几乎等于输入特征图。若s大于1，那么输出特征图缩小为原来的1/s左右。

Pooling层的作用是去除冗余信息。它把相邻的多个响应值合并为一个，因此它也降低了特征图的尺寸。通常，每一定数量的卷积层后面会被添加一个Pooling层，越到网络的高层，特征图的尺寸越低。这使得位于高层的小卷积核也获得了大的视野范围。根据合并方式的不同，可以分为Max-Pooling和Avg-Pooling，使用最广泛的是前者。另一个关键参数是窗口尺寸，一般是2，2。Pooling层中的滑动步长一般等于窗口尺寸，意味着滑动时不会出现重叠。Pooling层不是必需的，将卷积层的滑动步长设置为大于1的值同样可以降低特征图的尺寸。

CNN中的全连接层和前馈神经网络中的完全一样，此处不再赘述。有实验表明，利用最后一个卷积层输出的特征图训练一个SVM分类器，可以达到类似的识别精度。这说明CNN的卷积层部分是一个特征提取器，而最后的全连接层充当分类器。

##### 2.2.2 训练CNN

梯度求解

参数初始化

##### 2.2.3 常见模型

LeNet是由LeCun等人在90年代开发的用于手写数字识别的网络模型，识别率达到99%以上。它的主要结构是两层5，5卷积层加上两次2，2降采样。这是卷积神经网络的第一个成功应用，它显示CNN这种简洁的模型在处理图像识别上的巨大潜力。这可能激励了人们尝试开发更大规模的CNN以处理更复杂的物体识别。

2012年ImageNet图像识别比赛的获胜模型AlexNet证明了这是可以做到的，它实现了84%的top5识别率，远远超过使用传统方法的第二名获得的74%识别率。这项工作由Alex Krizhevsky等人完成，网络结构和LeNet类似，但是层数和卷积核数量都更多，总共有5个卷积层和三次降采样。它表明了CNN在处理复杂的图像识别问题上的有效性，促成了神经网络的再次流行，许多计算机视觉研究人员自此开始研究CNN。

2014年ImageNet的获胜模型VGGNet继续大幅度提升了识别性能，top5识别率达到了93%左右。它包含了13个卷积层和5次降采样。和AlexNet的明显区别是卷积层的数量增加了一倍多，它显示了CNN的层数对模型效果的决定性作用。然而，随着层数的增加，网络的训练越来越成为问题。

![近几年ImageNet比赛的获奖模型和识别率](https://www.bdti.com/sites/default/files/insidedsp/articlepix/201706/MicrosoftImagNetResults.png)

2015年何凯明等人在改进了网络结构并结合了其他人的多项工作后，训练出了超过100层的网络模型，ResNet。这也是当年ImageNet的获胜模型，top5识别率提升到96%左右。ResNet中引入的隔层连接显著改善了神经网络的训练难的问题，到目前（2017年末）ResNet仍然是CNN研究和应用的首选基准模型。本文的后续实验也都基于该模型。

#### 2.3 图像分类问题

图像分类是给一副图像分配一个或多个标签，指出图像描绘了什么场景、包含了什么物体等。只有进行了这样的转换，计算机才可以一定程度上理解图像，否则它只是一个没有任何语义信息的矩阵。图像分类是计算机视觉的核心问题，因为计算机视觉领域的大多数其他问题都可以被分解为分类问题，比如物体识别是在图像的多个位置进行分类，图像分割是在像素级别上分类。然而，这个基础问题又非常困难。图像的生成过程受很多因素影响，可以将其分为环境条件和自身变化两类。前者包括光照、拍摄角度和遮挡，后者的情况更加复杂，以人脸为例，个体的发型、饰物和表情变化都将显著改变图像矩阵的取值。这些因素的自由度都太大，对其正向建模几乎不可能。因此，以数据驱动位思想的机器学习方法更合适。卷积神经网络就是为分析图像而设计的一种机器学习模型，近些年成为图像分类的标准方法。本文也以在图像分类问题上的效果来衡量正则化方法对CNN的有效性。

##### 2.3.1 数据集

MNIST

Fashion-MNIST

CIFAR-10是一个很流行的图像分类测试数据集。它包含的是3通道的32，32尺寸的图像，类别包含了猫、狗等动物和轿车、轮船等交通工具共十个。图像总量是6万张，被划分为5万和1万的两个子集，一般分别被当做训练集和测试集。另有CIFAR-100数据集，包含的图像和CIFAR-10完全一致，不过类别的粒度更细，比如人被分为了婴儿、男孩和女孩等，总计有100个类别。

ImageNet

#### 2.4 过拟合与正则化

##### 2.4.1 VC维

##### 2.4.2 bias-variance困境

### 3. 显式正则化

训练神经网络时，我们是根据损失函数在训练集上的取值来调整参数的，这可以确保模型在训练集上取得好的效果，但是模型的价值是在测试集上体现的。神经网络作为一种通用的函数拟合手段，其被应用在特定问题时过拟合很容易发生。正则化就是通过设计一些策略，降低模型在测试集上的错误率（这可能会带来训练集误差的上升）。目前有很多针对卷积神经网络设计的正则化方法，可以归结到三类：作用于模型上的、作用于训练方法上的和作用于数据上的。作用于模型上的正则化方法是在网络结构上增加额外的层，训练和测试时这些层都和正常的节点层一样参与计算，代表性的有Dropout和Batch-Normalization；作用于训练方法上的正则化方法一般是修改梯度求解公式，比如在目标函数上添加一个额外项，它们只是训练时发挥作用，代表性方法有SGD和参数衰减；作用于数据上的正则化方法是修改数据集或标签，比如数据扩增和标签平滑。

#### 3.1 参数衰减

最常见的显示正则化方法是在损失函数 $J(w)$上添加权值的范式$O(w)$，我们用$J'(w)$来表示正则化后的损失函数$J'$
$$
J'(\theta) = J(\theta) + \lambda*O(\theta)
$$
$O(\theta)$和$\theta$的绝对值正相关，将其添加到损失函数，可以使得训练时同时降低原始损失函数和参数的范式。它限制了参数的变动空间，促使其向更小的绝对值、更多的零取值靠拢，从而限制了网络表示的函数的复杂度。 a是一个超参数，该值越大，正则化的作用越明显，不过太大的a值会干扰原始损失函数的下降。在实验中，可以根据$J(t)$和$O(t)$的数量级，选择适当的$\lambda$使得$\lambda*O(t)$的数量级和$J(t)$相当或者略小。$O(t)$仅定义在网络的连接权重上，而不包括偏置项，因为后者只充当常数项，不影响网络的复杂度。另外从训练时对数据的需求来看，连接权重更容易和过拟合相关，因为它影响的是两个节点的交互，需要观察到两个节点的各种取值的组合，而偏置只控制一个单一的节点。下文中，我们用$w$表示和正则相关的参数，$t$表示所有参数（包含$w$）。

以上是定性的分析，下面定量的分析$l2$正则是如何影响权值的更新方式和收敛的极值点的。$l2$正则又称为岭回归、Tikhonov正则，它通过添加$O(t) = \left\|w\right\|_{2}$到损失函数来实现。为了简化公式，且在不影响分析的前提下，我们假设没有偏置项，那么$\theta$就是$w$，那么

$$
J'(w) = \frac{1}{2} \lambda*\left\|w\right\|_{2} + J(w)
$$
其在$w$上的梯度是

$$
\nabla _w J = \lambda w + \nabla _w J
$$
按梯度下降法的更新公式，一次迭代是
$$
w = w - \epsilon (\lambda w + \nabla _w J) = (1-\epsilon \lambda)w - \epsilon \nabla _w J
$$
可以看到添加的正则项改变了梯度规则，其相当于每次先缩小w，再执行和原来一样的更新。这是单次更新的情况，我们需要知道正则项对w最后的收敛值有什么影响。梯度下降法的收敛于梯度为0的地方，即驻点。令$w^*=arg min J(w)$为没有正则化的收敛点，我们用二阶泰勒展开式近似$J(w)$在$w^*$附近的取值。
$$
J(w) = J(w^{*}) + 1/2(w-w^{*})^{T}H(w-w^{*})
$$
其中，$H$是$J$在$w^*$处的黑塞矩阵。根据驻点的定义，可以得到
$$
H(w-w^{*}) = 0
$$
设$w1$为有$l2$正则项的损失函数的驻点，有
$$
H(w-w1) + a*w = 0 => w1 = {(H + aI)}^{-1}Hw^{*}
$$

因为黑塞矩阵H是实对称的，可以被分解为$H=Q\Lambda Q^T$，$Q$是正交矩阵。应用到上面的式子，有
$$
w1=Q(\Lambda  + \alpha I)^{-1}Q^T w^*
$$
可以看出$l2$正则使得$w^*$按照$H$的特征向量定义的方向缩放，各个方向缩放的比例是$s=\frac {\lambda _i}{\lambda _i + \alpha}$。当$\lambda _i$靠近0时，$s$取得很小的值，对应的权重$w_i$会显著变小；当$\lambda _i$比较大时，s接近1，对应的权重$w _i$基本保持不变。而特征值代表了对应方向上的特征对目标函数的影响能力，l2正则进一步使得不重要的特征的权值减小，而重要的特征的权值得以保留。另外一种通用的权值衰减项是$l1$正则，它把$\Omega(\theta)= \left\|w\right\|_1$加到损失函数上。通过和上面类似的推导步骤可以知道，$l1$范式可以使得某些连接权重为0，这和稀疏编码的思想有些相似。下图形象地展示了$l1$和$l2$正则是如何改变损失函数的极值点的。

![L1 & L2 weight decay](http://hpzhao.com/images/L2_4.png)

#### 3.2 随机梯度下降

神经网络的训练是一个非凸优化问题，可以被表示为
$$
min J(w) = \frac{1}{|M|} \Sigma J_i(w)
$$
M代表整个数据集，$J_i(w)$是损失函数在第$i$条数据上的取值。按照梯度下降的定义，应当求解$J$在所有数据上的平均梯度，但实际上几乎没有人这么做，而是随机的从数据集中选取一个很小的子集计算。基于这种梯度计算方式的梯度下降法被称为随机梯度下降法（SGD），其已经成为深度学习社区的标准优化方法。Bottou等人证明了它在非凸问题上可以收敛到平稳点，Ge等人的工作表明SGD可以帮助逃离非凸函数上广泛分布的鞍点。一次更新的公式如下
$$
w_{t+1}=w_t-\epsilon(\frac{1}{|B|} \Sigma {\nabla J_i(w)})
$$
B代表从M中随机抽取出的固定大小的子集，满足$|B|<<|M|$，通常$|B|\in {\{32,64,…,512}\}$。这种修改可以带来两个好处。第一，它使得梯度计算的时间复杂度不再和数据集大小成正比，而是一个常数。在百万级的数据集上，SGD相比原始的GD算法有上万倍的加速。第二，它为训练出的网络模型带来了更好的泛化能力。SGD训练出的网络比GD泛化性能好，基于较小batch-size（几十）的SGD相比较大batch-size（几百）的SGD，泛化性能还有进一步提升。Nitish等人研究了使用不同的batch-size训练的收敛点附近的性质，发现batch-size和损失函数在收敛点附近的黑塞矩阵的特征值的绝对值成负相关。他们的实验证实了，基于小batch-size的SGD因梯度估计偏差而引入的噪声非但没有干扰网络收敛，而且帮助网络逃离了陡峭的极值点而收敛于平坦的区域。

![平坦和陡峭的极值点](http://www.inference.vc/content/images/2017/05/Screen-Shot-2017-05-25-at-1.36.40-PM.png)

平坦的极值点意味着函数在这附近较大区域内的变化率都很小，而陡峭的极值点表示附近很小区域内的变化率就比较大。大的变化率会对泛化能力造成负面影响，这可以通过信息论中的最小描述长度（MDL）理论解释，MDL值越小的统计模型具有更低的复杂度，泛化能力可能也更好。平坦区域的MDL比陡峭区域小，因此是更好的收敛点。

#### 3.3 Dropout

背景

在机器学习竞赛中出现频率很高的一种提升模型测试性能的方法是集成学习（ensemble learning），以bagging和boosting为代表。它们的基本思想都是使用多个弱分类器合成一个强分类器：bagging是从数据集中独立抽取M个子集，使用这些子集独立训练出M个分类模型，集成模型的输出由投票机制求得，即获得最多模型支持的为输出类别；boosting方法给样本增加了权重，每个样本对损失函数的贡献和权重成正比，每次训练结束后增加被误分样本的权重，那么在下一次迭代时模型会更加偏向这些样本，集成模型的输出由这些模型的加权组合得到。

方法

![正常网络和Dropout网络](https://www.researchgate.net/profile/Giorgio_Roffo/publication/317277576/figure/fig23/AS:500357438869504@1496305917227/Figure-7-9-An-illustration-of-the-dropout-mechanism-within-the-proposed-CNN-a-Shows-a.png)

Dropout是bagging在神经网络上的一种高效近似，对于一个给定的网络结构，我们可以移除其中某些节点而得到一个更简单的网络，移除的策略有非常多种，如果非输出层节点都可以被移除并且其数量是N的话，那么有$2^N-1$种不同的简单网络。单独训练这些简单网络然后集成它们的结果，我们可以期待显著的测试性能提升。但这不具备可行性，因为模型数量过于巨大。Dropout的做法是在训练时每个节点乘以一个服从伯努利分布的随机变量$x$，而在测试时节点的输出等于激活值乘以随机变量的期望$E(x)$。训练阶段，网络关于每条数据的前向计算都会对$x$采样，如果采样值为$0$，无论激活值是多少该节点的输出都为$0$，就好像这个节点以及它前后的连接都被移除了；如果采样值为$1$，那么该节点得以保留，输出值和激活值一样。

按照bagging的定义，集成模型的输出应当是所有简单模型的输出的算术平均，Bengio等人使用几何平均近似算术平均，并假设网络是一个单层的softmax分类器的情况下，推导出了集成结果等于权值缩放后的单个网络的结果。这个结论在不包含非线性激活函数的深层网络中也成立，在包含非线性激活函数的网络上的实验表明dropout可以很好的工作。获得集成输出的另一种高效方法是抽样近似，Goodfellow等人在实验中发现其效果不如权值缩放，即便是抽取上千个子网，但是Gal等人发现在有些模型上二十个子网络样本的集成效果就比权值缩放后的单个网络好了。Srivastava等人的工作表明Dropout的效果比其他不显著增加成本的正则化方法效果好，比如$l1$和$l2$正则。并且，Dropout可以和这些正则化方法一起使用，以获得额外的测试性能提升。

Droput带来的好处也并不是完全没有成本的。实验表明它会减缓模型的收敛速度，从而增加训练时间。可能的原因是，子网络的权值是共享的，每次更新权重都会修改到许多子网络的部分权重，而不像训练单个网络时所有权重会被同步更新。也可以从梯度噪声的角度解释，那些乘零操作可被看做一种随机噪声，噪声引起的梯度偏差干扰了梯度下降法，但是也增加了模型的泛化能力，就像随机梯度下降法中的噪声一样。Srivastava的工作表明使用一个随机性更强的均值为$1$的正态分布替换伯努利分布，模型表现会显著优于原始的Dropout。这增加了Dropout是一种基于噪声的正则化方法的观点的可信度。

#### 3.4 Batch Normalization

背景

很多问题的输入特征的维度都会比较高，复杂的线性回归可能涉及数十到数百个变量，而图像通常都是由上万个像素组成的。不同维度的特征的数量级（scale）可能有很大的差别，大量级的特征对模型输出的贡献也大，这样就可能出现小量级的特征被抑制，模型输出主要由少数大量级特征决定的情况。因此，我们在应用机器学习解决实际问题时，通常会先对特征做标准化（Normalization）预处理。具体的，使用下面的变换使得各个特征具有零均值和单位方差。
$$
x_i=\frac{x_i-\overline {x_i}}{\sigma _{x_i}}
$$
在具备层次化结构的神经网络中，情况会更加复杂。输入特征会经过多次变换，其分布会不断变化。某一层的输入由前面所有层的参数决定，所以微弱的参数变动也会在网络中被放大，数据的标准化特性在前向传播过程中难以被保留。Sergey Ioffe等人提出了Batch Normalization（BN）方法，其主要作用是加速网络训练，并同时带来了正则化的效果。

方法

BN层是一种独立的神经网络组件，可以被应用到任一隐含层。设$m*n$的矩阵$H$是某一层的输入特征，$m$是batch size，$n$是特征维度，$i$是样本的索引，$j$是特征的索引，BN的输入输出关系由下面的式子定义。
$$
BN(H_{ij})=\frac{H_{ij}-u_j}{\sigma _j}
$$

$$
\mu _j=\frac{1}{m}\sum_{i=1}^{m}H_{ij}
$$

$$
\sigma _j=\sqrt{\epsilon+\frac{1}{m}\sum_{i=1}^m (H_{ij}-\mu _j)^2}
$$

其中，用于标准化的均值$u$和方差$\sigma$是常数，训练时由batch内的数据计算得到，测试时由整个数据集算得。

BN已被许多实验结果验证了有效性，自被提出后已经被应用到了很多种网络结构中，都能够取得加速训练和减小测试误差的效果，比如目前最流行的ResNet重度使用了这种结构。尽管如此，它的工作原理仍然不是很明确，深度学习社区也没有非常一致的看法。BN的提出者Sergey Ioffe在其论文中使用了"Internal Covariant Shift"来解释，"Covariant Shift"是迁移学习中的一个概念，它指出特征分布的偏移会导致已训练好的判别函数的失效，因为判别函数的学习依赖了误差在特征分布上的期望。神经网络训练时，参数变化会导致每一层的输出的分布都发生改变，作者把这种存在于相邻隐含层的分布偏移称之为"Internal Covariant Shift"，而BN的加入可以基本固定每一层输出的分布的均值和方差。笔者认为这样的解释有明显的漏洞，"Covariant Shift"的适用场景是映射关系$y=F(x)$相同、自变量$x$的分布不同，而神经网络中每层的映射本身是不同的，因此这个概念并不适用于神经网络。另外，当我们讨论$x$的分布时，应当是针对其所有分量的联合分布，单独标准化每个分量对联合分布的影响是未知的。\<Deep Learning\>一书中针对BN给出了不一样的分析，它以一个极为简化的由单节点层组合的网络为例，说明了神经网络模型的局部不能够线性近似，只考虑一阶梯度的SGD会产生意想不到的结果，但是没有推导BN是如何解决这样的问题的，也没有说明简化模型的分析能否泛化到更一般的神经网络。

另外，实际应用BN层时，标准化操作后面会有一个额外的线性变换，设$H^{'}$是标准化后的特征，BN的实际输出等于$H^{'}*\gamma+\beta$，其中$\gamma $和$\beta$是可训练的参数，分别被初始化为$1$和$0$。原论文的解释是，标准化会减弱神经网络的表达力，$\gamma$和$\beta$的加入就是为了弥补这种损失。这似乎和添加BN层的目的背道而驰，但是在实验中起到了好的效果。一个有意义的实验是去掉这个线性变换，BN层还能很好的发挥作用吗？遗憾的是，原论文中没有相关的论证。

BN层除了稳定分布和加速训练的功能，还可以显著降低测试误差，所以它也是一个重要的正则化方法。其带来的泛化能力提升可以归结到随机噪声的框架下，就像SGD带来的梯度噪声那样。BN层进行标准化时，使用的均值和方差是在一个batch的数据上求得的。样本的丰富性和抽样的随机性会使得每一个batch，使用的均值和方差不一样；同一个样本的每一次出现，使用的均值和方差也不一样。

尽管其原理尚未明确，但BN仍然是近几年深度学习研究领域最重要的成果之一。

#### 3.5 数据扩增

背景

大多数机器学习模型都可以在更大的数据集上取得更好的表现。如果模型的训练可以看成函数拟合的过程，更多的数据可以更准确的描述数据的分布，从而降低离群点（outlier）对模型的影响。所需的数据量和特征空间的容量（capacity）正相关，而这又和特征的维度呈指数关系。随着特征维度的增加，模型对数据的需求会变得十分苛刻。这在CNN上体现得很明显，因为它要处理的图像数据通常都是数万到数百万像素的。然而，在处理实际问题时可用的数据是有限的，获取新的标注数据的成本可能很昂贵。一种解决方法是使用现有数据合成新数据并加入到训练集，这就是数据扩增。一般的做法是对特征$x$施加某种变换（transform）$F(x)$，但不改变目标变量$y$的取值。变换不会造成目标信息的改变，这一点非常重要，否则我们生成的数据和原始数据集表达的映射关系是不一致的，从而对模型训练造成负面干扰。选择什么样的变换，需要利用领域知识（domain knowledge），厘清哪些因素是输出的因变量，而哪些因素是无关变量，数据扩增一般就是对后者的模拟（simulation）。

方法：仿射变换、对比度变换、亮度变换

对于基于CNN的图像分类问题，数据扩增特别容易实施。图像的生成过程受到众多因素影响，诸如光源位置、光照强度、拍摄距离和拍摄角度等，可以说每一张照片都不可避免的和这些因素相关，但是它们不影响我们识别出里面的物体的类别。这些因素，一方面增加了模型泛化的难度，另一方面也给数据扩增提供了条件。模拟这些因素的变化，可以得到一幅图像的多个变体。对整个数据集做这样的操作，数据量可以被扩大数倍到数十倍。大量实验室证明了数据扩增的有效性。LeCun在提出LeNet的论文中针对MNIST数据集使用了一系列复杂的图像变换，这也是第一个成功的CNN模型；Krizhevsky等人利用随机裁剪、水平翻转和PCA分析[??]使得AlexNet的Top-1识别率提升了超过1%；2014年ILSVRC的冠军模型VGGNet还额外使用了缩放操作扩增数据集。

![图像扩增](https://cdn-images-1.medium.com/max/1200/1*5RXJ2OlVJp4_sd1XzhK6pQ.png)

这些工作都使用了多种扩增操作，也没有分析单一操作的贡献。Chiyuan Zhang等人报告简单的随机裁剪可以大幅提升Inception在ImageNet数据集上的识别率，从59.80%到67.18%。其他策略，例如调整图像的尺寸、对比度和光照等特性也可以产生一定的正则化效果。虽然没有独立的对比实验，但是经验告诉我们这些操作的提升远不如随机裁剪。裁剪操作的高度有效性是一个值得研究的课题。

数据扩增的陷阱：不能引入改变信息的操作。

### 4. 正则化对模型识别率的影响



### 5. 正则化对模型稳定性的影响

### 6. 一种新的正则化方法：特征扩增

#### 6.1 定义

#### 6.2 实验

#### 6.3 分析

### 7. 总结

